{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K4f4JG1gdKqj"},"source":["#AutoEncoders"]},{"cell_type":"markdown","metadata":{"id":"1jbiqOK7dLGG"},"source":["##Downloading the dataset"]},{"cell_type":"markdown","metadata":{"id":"XL5MEkLcfRD2"},"source":["###ML-100K"]},{"cell_type":"code","metadata":{"id":"rjOPzue7FCXJ","outputId":"69a3ddbb-2168-4890-a0cf-8377efe26d79","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665045545458,"user_tz":-330,"elapsed":1180,"user":{"displayName":"VIJAY SIVA (RA2213004011007)","userId":"05254700740973856188"}}},"source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n","!unzip ml-100k.zip\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-06 08:38:54--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4924029 (4.7M) [application/zip]\n","Saving to: ‘ml-100k.zip’\n","\n","ml-100k.zip         100%[===================>]   4.70M  2.68MB/s    in 1.8s    \n","\n","2022-10-06 08:38:56 (2.68 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n","\n","Archive:  ml-100k.zip\n","   creating: ml-100k/\n","  inflating: ml-100k/allbut.pl       \n","  inflating: ml-100k/mku.sh          \n","  inflating: ml-100k/README          \n","  inflating: ml-100k/u.data          \n","  inflating: ml-100k/u.genre         \n","  inflating: ml-100k/u.info          \n","  inflating: ml-100k/u.item          \n","  inflating: ml-100k/u.occupation    \n","  inflating: ml-100k/u.user          \n","  inflating: ml-100k/u1.base         \n","  inflating: ml-100k/u1.test         \n","  inflating: ml-100k/u2.base         \n","  inflating: ml-100k/u2.test         \n","  inflating: ml-100k/u3.base         \n","  inflating: ml-100k/u3.test         \n","  inflating: ml-100k/u4.base         \n","  inflating: ml-100k/u4.test         \n","  inflating: ml-100k/u5.base         \n","  inflating: ml-100k/u5.test         \n","  inflating: ml-100k/ua.base         \n","  inflating: ml-100k/ua.test         \n","  inflating: ml-100k/ub.base         \n","  inflating: ml-100k/ub.test         \n","ml-100k  ml-100k.zip  sample_data\n"]}]},{"cell_type":"markdown","metadata":{"id":"9Xis6ldDfTs6"},"source":["###ML-1M"]},{"cell_type":"code","metadata":{"id":"LOly1yfAfTjd","outputId":"82c7dcb3-6c18-42f8-b571-f5b568583444","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665045568212,"user_tz":-330,"elapsed":2699,"user":{"displayName":"VIJAY SIVA (RA2213004011007)","userId":"05254700740973856188"}}},"source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n","!unzip ml-1m.zip\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-06 08:39:17--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5917549 (5.6M) [application/zip]\n","Saving to: ‘ml-1m.zip’\n","\n","ml-1m.zip           100%[===================>]   5.64M  3.20MB/s    in 1.8s    \n","\n","2022-10-06 08:39:19 (3.20 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n","\n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n","ml-100k  ml-100k.zip  ml-1m  ml-1m.zip\tsample_data\n"]}]},{"cell_type":"markdown","metadata":{"id":"EOBJ8UCXdY0g"},"source":["##Importing the libraries"]},{"cell_type":"code","metadata":{"id":"_LvGeU1CeCtg"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pM04FyMudkoK"},"source":["## Importing the dataset\n"]},{"cell_type":"code","metadata":{"id":"UJw2p3-Cewo4"},"source":["# We won't be using this dataset.\n","movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTIbE2tkdkwP"},"source":["## Preparing the training set and the test set\n"]},{"cell_type":"code","metadata":{"id":"2usLKJBEgPE2"},"source":["training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n","training_set = np.array(training_set, dtype = 'int')\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n","test_set = np.array(test_set, dtype = 'int')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zCf8HjSydk4s"},"source":["## Getting the number of users and movies\n"]},{"cell_type":"code","metadata":{"id":"gPaGZqdniC5m"},"source":["nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n","nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-w4-hVidlAm"},"source":["## Converting the data into an array with users in lines and movies in columns\n"]},{"cell_type":"code","metadata":{"id":"-wASs2YFiDaa"},"source":["def convert(data):\n","  new_data = []\n","  for id_users in range(1, nb_users + 1):\n","    id_movies = data[:, 1] [data[:, 0] == id_users]\n","    id_ratings = data[:, 2] [data[:, 0] == id_users]\n","    ratings = np.zeros(nb_movies)\n","    ratings[id_movies - 1] = id_ratings\n","    new_data.append(list(ratings))\n","  return new_data\n","training_set = convert(training_set)\n","test_set = convert(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AMmhuUpldlHo"},"source":["## Converting the data into Torch tensors\n"]},{"cell_type":"code","metadata":{"id":"TwD-KD8yiEEw"},"source":["training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kkL8NkkdlZj"},"source":["## Creating the architecture of the Neural Network\n"]},{"cell_type":"code","metadata":{"id":"oU2nyh76iE6M"},"source":["class SAE(nn.Module):\n","    def __init__(self, ):\n","        super(SAE, self).__init__()\n","        self.fc1 = nn.Linear(nb_movies, 20)\n","        self.fc2 = nn.Linear(20, 10)\n","        self.fc3 = nn.Linear(10, 20)\n","        self.fc4 = nn.Linear(20, nb_movies)\n","        self.activation = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.activation(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","sae = SAE()\n","criterion = nn.MSELoss()\n","optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gy59alAdloL"},"source":["## Training the SAE\n"]},{"cell_type":"code","metadata":{"id":"FEz9hRaciFTs","outputId":"e4333e59-7d55-4147-aa21-5e27605037cf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665045959998,"user_tz":-330,"elapsed":241247,"user":{"displayName":"VIJAY SIVA (RA2213004011007)","userId":"05254700740973856188"}}},"source":["nb_epoch = 200\n","for epoch in range(1, nb_epoch + 1):\n","  train_loss = 0\n","  s = 0.\n","  for id_user in range(nb_users):\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","    target = input.clone()\n","    if torch.sum(target.data > 0) > 0:\n","      output = sae(input)\n","      target.require_grad = False\n","      output[target == 0] = 0\n","      loss = criterion(output, target)\n","      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","      loss.backward()\n","      train_loss += np.sqrt(loss.data*mean_corrector)\n","      s += 1.\n","      optimizer.step()\n","  print('epoch: '+str(epoch)+'loss: '+ str(train_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1loss: tensor(1.7719)\n","epoch: 2loss: tensor(1.0967)\n","epoch: 3loss: tensor(1.0535)\n","epoch: 4loss: tensor(1.0385)\n","epoch: 5loss: tensor(1.0311)\n","epoch: 6loss: tensor(1.0266)\n","epoch: 7loss: tensor(1.0238)\n","epoch: 8loss: tensor(1.0220)\n","epoch: 9loss: tensor(1.0206)\n","epoch: 10loss: tensor(1.0195)\n","epoch: 11loss: tensor(1.0186)\n","epoch: 12loss: tensor(1.0185)\n","epoch: 13loss: tensor(1.0178)\n","epoch: 14loss: tensor(1.0177)\n","epoch: 15loss: tensor(1.0172)\n","epoch: 16loss: tensor(1.0170)\n","epoch: 17loss: tensor(1.0167)\n","epoch: 18loss: tensor(1.0165)\n","epoch: 19loss: tensor(1.0165)\n","epoch: 20loss: tensor(1.0162)\n","epoch: 21loss: tensor(1.0160)\n","epoch: 22loss: tensor(1.0162)\n","epoch: 23loss: tensor(1.0157)\n","epoch: 24loss: tensor(1.0159)\n","epoch: 25loss: tensor(1.0155)\n","epoch: 26loss: tensor(1.0155)\n","epoch: 27loss: tensor(1.0155)\n","epoch: 28loss: tensor(1.0152)\n","epoch: 29loss: tensor(1.0136)\n","epoch: 30loss: tensor(1.0122)\n","epoch: 31loss: tensor(1.0097)\n","epoch: 32loss: tensor(1.0094)\n","epoch: 33loss: tensor(1.0056)\n","epoch: 34loss: tensor(1.0055)\n","epoch: 35loss: tensor(1.0016)\n","epoch: 36loss: tensor(1.0003)\n","epoch: 37loss: tensor(0.9964)\n","epoch: 38loss: tensor(0.9938)\n","epoch: 39loss: tensor(0.9920)\n","epoch: 40loss: tensor(0.9940)\n","epoch: 41loss: tensor(0.9883)\n","epoch: 42loss: tensor(0.9858)\n","epoch: 43loss: tensor(0.9841)\n","epoch: 44loss: tensor(0.9837)\n","epoch: 45loss: tensor(0.9811)\n","epoch: 46loss: tensor(0.9803)\n","epoch: 47loss: tensor(0.9768)\n","epoch: 48loss: tensor(0.9762)\n","epoch: 49loss: tensor(0.9713)\n","epoch: 50loss: tensor(0.9705)\n","epoch: 51loss: tensor(0.9668)\n","epoch: 52loss: tensor(0.9675)\n","epoch: 53loss: tensor(0.9633)\n","epoch: 54loss: tensor(0.9623)\n","epoch: 55loss: tensor(0.9616)\n","epoch: 56loss: tensor(0.9620)\n","epoch: 57loss: tensor(0.9586)\n","epoch: 58loss: tensor(0.9580)\n","epoch: 59loss: tensor(0.9557)\n","epoch: 60loss: tensor(0.9549)\n","epoch: 61loss: tensor(0.9521)\n","epoch: 62loss: tensor(0.9518)\n","epoch: 63loss: tensor(0.9497)\n","epoch: 64loss: tensor(0.9501)\n","epoch: 65loss: tensor(0.9477)\n","epoch: 66loss: tensor(0.9482)\n","epoch: 67loss: tensor(0.9459)\n","epoch: 68loss: tensor(0.9466)\n","epoch: 69loss: tensor(0.9445)\n","epoch: 70loss: tensor(0.9446)\n","epoch: 71loss: tensor(0.9432)\n","epoch: 72loss: tensor(0.9434)\n","epoch: 73loss: tensor(0.9419)\n","epoch: 74loss: tensor(0.9423)\n","epoch: 75loss: tensor(0.9414)\n","epoch: 76loss: tensor(0.9413)\n","epoch: 77loss: tensor(0.9397)\n","epoch: 78loss: tensor(0.9403)\n","epoch: 79loss: tensor(0.9386)\n","epoch: 80loss: tensor(0.9395)\n","epoch: 81loss: tensor(0.9396)\n","epoch: 82loss: tensor(0.9471)\n","epoch: 83loss: tensor(0.9442)\n","epoch: 84loss: tensor(0.9435)\n","epoch: 85loss: tensor(0.9401)\n","epoch: 86loss: tensor(0.9406)\n","epoch: 87loss: tensor(0.9381)\n","epoch: 88loss: tensor(0.9388)\n","epoch: 89loss: tensor(0.9367)\n","epoch: 90loss: tensor(0.9377)\n","epoch: 91loss: tensor(0.9355)\n","epoch: 92loss: tensor(0.9361)\n","epoch: 93loss: tensor(0.9346)\n","epoch: 94loss: tensor(0.9353)\n","epoch: 95loss: tensor(0.9332)\n","epoch: 96loss: tensor(0.9345)\n","epoch: 97loss: tensor(0.9325)\n","epoch: 98loss: tensor(0.9338)\n","epoch: 99loss: tensor(0.9316)\n","epoch: 100loss: tensor(0.9326)\n","epoch: 101loss: tensor(0.9306)\n","epoch: 102loss: tensor(0.9316)\n","epoch: 103loss: tensor(0.9304)\n","epoch: 104loss: tensor(0.9308)\n","epoch: 105loss: tensor(0.9292)\n","epoch: 106loss: tensor(0.9299)\n","epoch: 107loss: tensor(0.9286)\n","epoch: 108loss: tensor(0.9292)\n","epoch: 109loss: tensor(0.9279)\n","epoch: 110loss: tensor(0.9288)\n","epoch: 111loss: tensor(0.9271)\n","epoch: 112loss: tensor(0.9279)\n","epoch: 113loss: tensor(0.9266)\n","epoch: 114loss: tensor(0.9271)\n","epoch: 115loss: tensor(0.9258)\n","epoch: 116loss: tensor(0.9264)\n","epoch: 117loss: tensor(0.9252)\n","epoch: 118loss: tensor(0.9260)\n","epoch: 119loss: tensor(0.9248)\n","epoch: 120loss: tensor(0.9254)\n","epoch: 121loss: tensor(0.9241)\n","epoch: 122loss: tensor(0.9247)\n","epoch: 123loss: tensor(0.9236)\n","epoch: 124loss: tensor(0.9240)\n","epoch: 125loss: tensor(0.9231)\n","epoch: 126loss: tensor(0.9234)\n","epoch: 127loss: tensor(0.9224)\n","epoch: 128loss: tensor(0.9231)\n","epoch: 129loss: tensor(0.9221)\n","epoch: 130loss: tensor(0.9225)\n","epoch: 131loss: tensor(0.9215)\n","epoch: 132loss: tensor(0.9220)\n","epoch: 133loss: tensor(0.9212)\n","epoch: 134loss: tensor(0.9214)\n","epoch: 135loss: tensor(0.9206)\n","epoch: 136loss: tensor(0.9209)\n","epoch: 137loss: tensor(0.9202)\n","epoch: 138loss: tensor(0.9206)\n","epoch: 139loss: tensor(0.9197)\n","epoch: 140loss: tensor(0.9200)\n","epoch: 141loss: tensor(0.9192)\n","epoch: 142loss: tensor(0.9195)\n","epoch: 143loss: tensor(0.9187)\n","epoch: 144loss: tensor(0.9190)\n","epoch: 145loss: tensor(0.9184)\n","epoch: 146loss: tensor(0.9185)\n","epoch: 147loss: tensor(0.9180)\n","epoch: 148loss: tensor(0.9183)\n","epoch: 149loss: tensor(0.9178)\n","epoch: 150loss: tensor(0.9180)\n","epoch: 151loss: tensor(0.9171)\n","epoch: 152loss: tensor(0.9175)\n","epoch: 153loss: tensor(0.9166)\n","epoch: 154loss: tensor(0.9172)\n","epoch: 155loss: tensor(0.9160)\n","epoch: 156loss: tensor(0.9167)\n","epoch: 157loss: tensor(0.9159)\n","epoch: 158loss: tensor(0.9164)\n","epoch: 159loss: tensor(0.9157)\n","epoch: 160loss: tensor(0.9162)\n","epoch: 161loss: tensor(0.9154)\n","epoch: 162loss: tensor(0.9157)\n","epoch: 163loss: tensor(0.9149)\n","epoch: 164loss: tensor(0.9152)\n","epoch: 165loss: tensor(0.9146)\n","epoch: 166loss: tensor(0.9151)\n","epoch: 167loss: tensor(0.9145)\n","epoch: 168loss: tensor(0.9149)\n","epoch: 169loss: tensor(0.9142)\n","epoch: 170loss: tensor(0.9147)\n","epoch: 171loss: tensor(0.9140)\n","epoch: 172loss: tensor(0.9144)\n","epoch: 173loss: tensor(0.9138)\n","epoch: 174loss: tensor(0.9142)\n","epoch: 175loss: tensor(0.9135)\n","epoch: 176loss: tensor(0.9138)\n","epoch: 177loss: tensor(0.9131)\n","epoch: 178loss: tensor(0.9134)\n","epoch: 179loss: tensor(0.9129)\n","epoch: 180loss: tensor(0.9133)\n","epoch: 181loss: tensor(0.9126)\n","epoch: 182loss: tensor(0.9130)\n","epoch: 183loss: tensor(0.9124)\n","epoch: 184loss: tensor(0.9128)\n","epoch: 185loss: tensor(0.9122)\n","epoch: 186loss: tensor(0.9125)\n","epoch: 187loss: tensor(0.9120)\n","epoch: 188loss: tensor(0.9123)\n","epoch: 189loss: tensor(0.9117)\n","epoch: 190loss: tensor(0.9121)\n","epoch: 191loss: tensor(0.9116)\n","epoch: 192loss: tensor(0.9119)\n","epoch: 193loss: tensor(0.9114)\n","epoch: 194loss: tensor(0.9117)\n","epoch: 195loss: tensor(0.9111)\n","epoch: 196loss: tensor(0.9115)\n","epoch: 197loss: tensor(0.9109)\n","epoch: 198loss: tensor(0.9112)\n","epoch: 199loss: tensor(0.9108)\n","epoch: 200loss: tensor(0.9110)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Bak5uc8gd-gX"},"source":["## Testing the SAE\n"]},{"cell_type":"code","metadata":{"id":"5ztvzYRtiGCz","outputId":"676bcc94-b3ee-4c57-8c2a-287b538e8cdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665046208643,"user_tz":-330,"elapsed":917,"user":{"displayName":"VIJAY SIVA (RA2213004011007)","userId":"05254700740973856188"}}},"source":["test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","  input = Variable(training_set[id_user]).unsqueeze(0)\n","  target = Variable(test_set[id_user]).unsqueeze(0)\n","  if torch.sum(target.data > 0) > 0:\n","    output = sae(input)\n","    target.require_grad = False\n","    output[target == 0] = 0\n","    loss = criterion(output, target)\n","    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","    test_loss += np.sqrt(loss.data*mean_corrector)\n","    s += 1.\n","print('test loss: '+str(test_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test loss: tensor(0.9509)\n"]}]}]}